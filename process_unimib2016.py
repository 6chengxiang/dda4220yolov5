#!/usr/bin/env python3
"""
UNIMIB2016 æ•°æ®é›†å¤„ç†è„šæœ¬
UNIMIB2016 Dataset Processing Script

ä¸“é—¨ç”¨äºå¤„ç†ä» Kaggle ä¸‹è½½çš„ UNIMIB2016 é£Ÿç‰©æ•°æ®é›†
"""

import os
import shutil
import argparse
from pathlib import Path
import random
from PIL import Image
import json
import zipfile

# UNIMIB2016 ç±»åˆ«æ˜ å°„
UNIMIB2016_CLASSES = {
    'bread': 0, 'pasta_with_tomato_sauce': 1, 'pasta_with_meat_sauce': 2,
    'pasta_with_clam_sauce': 3, 'pasta_with_pesto_sauce': 4, 'pasta_with_oil_and_garlic': 5,
    'gnocchi_with_tomato_sauce': 6, 'gnocchi_with_pesto_sauce': 7, 'risotto': 8,
    'polenta': 9, 'pizza_margherita': 10, 'pizza_four_cheese': 11,
    'pizza_with_vegetables': 12, 'pizza_with_ham': 13, 'focaccia': 14,
    'fagottini_peas_ham': 15, 'tagliatelle_with_sauce': 16, 'meatballs_with_tomato_sauce': 17,
    'baked_pasta': 18, 'pasta_salad': 19, 'minestrone': 20,
    'fish_soup': 21, 'vegetable_soup': 22, 'tripe': 23,
    'pasta_e_fagioli': 24, 'ribollita': 25, 'grilled_fish': 26,
    'mixed_fried_fish': 27, 'battered_fish': 28, 'roasted_chicken': 29,
    'chicken_breast': 30, 'chicken_wings': 31, 'fried_chicken': 32,
    'veal_cutlet': 33, 'grilled_beef': 34, 'beef_stew': 35,
    'roasted_beef': 36, 'hamburger': 37, 'pork_cutlet': 38,
    'pork_loin': 39, 'roasted_pork': 40, 'raw_ham': 41,
    'cooked_ham': 42, 'fried_egg': 43, 'scrambled_egg': 44,
    'boiled_egg': 45, 'omelette': 46, 'cheese': 47,
    'mozzarella': 48, 'cottage_cheese': 49, 'yogurt': 50,
    'apple': 51, 'banana': 52, 'orange': 53,
    'strawberry': 54, 'grapes': 55, 'pear': 56,
    'peach': 57, 'lemon': 58, 'kiwi': 59,
    'pineapple': 60, 'mixed_salad': 61, 'carrots': 62,
    'green_beans': 63, 'spinach': 64, 'tomatoes': 65,
    'potatoes': 66, 'french_fries': 67, 'roasted_potatoes': 68,
    'boiled_potatoes': 69, 'potato_gnocchi': 70, 'wine': 71, 'water': 72
}

def extract_kaggle_dataset(zip_path, extract_dir):
    """è§£å‹ä» Kaggle ä¸‹è½½çš„æ•°æ®é›†"""
    print(f"ğŸ“¦ è§£å‹æ•°æ®é›†: {zip_path}")
    
    extract_path = Path(extract_dir)
    extract_path.mkdir(parents=True, exist_ok=True)
    
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_path)
    
    print(f"âœ… è§£å‹å®Œæˆåˆ°: {extract_path}")
    return extract_path

def process_unimib2016(source_dir, target_dir, train_ratio=0.7, val_ratio=0.2):
    """
    å¤„ç† UNIMIB2016 æ•°æ®é›†
    
    é¢„æœŸçš„æºç›®å½•ç»“æ„å¯èƒ½æ˜¯ï¼š
    source_dir/
    â”œâ”€â”€ pre8/
    â”‚   â”œâ”€â”€ bread/
    â”‚   â”œâ”€â”€ pasta_with_tomato_sauce/
    â”‚   â””â”€â”€ ...
    æˆ–è€…ç›´æ¥ï¼š
    source_dir/
    â”œâ”€â”€ bread/
    â”œâ”€â”€ pasta_with_tomato_sauce/
    â””â”€â”€ ...
    """
    source_path = Path(source_dir)
    target_path = Path(target_dir)
    
    # åˆ›å»ºç›®æ ‡ç›®å½•ç»“æ„
    target_dirs = [
        target_path / 'images' / 'train',
        target_path / 'images' / 'val',
        target_path / 'images' / 'test'
    ]
    
    for dir_path in target_dirs:
        dir_path.mkdir(parents=True, exist_ok=True)
    
    print(f"ğŸ“ å¤„ç† UNIMIB2016 æ•°æ®é›†")
    print(f"ğŸ” æºç›®å½•: {source_path}")
    print(f"ğŸ“¦ ç›®æ ‡ç›®å½•: {target_path}")
    
    # æŸ¥æ‰¾å®é™…çš„æ•°æ®ç›®å½•
    data_dirs = []
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ pre8 å­ç›®å½•
    if (source_path / 'pre8').exists():
        data_root = source_path / 'pre8'
        print(f"ğŸ“‚ æ‰¾åˆ° pre8 ç›®å½•ï¼Œä½¿ç”¨: {data_root}")
    else:
        data_root = source_path
        print(f"ğŸ“‚ ç›´æ¥ä½¿ç”¨æºç›®å½•: {data_root}")
    
    # æŸ¥æ‰¾æ‰€æœ‰ç±»åˆ«ç›®å½•
    for item in data_root.iterdir():
        if item.is_dir() and item.name in UNIMIB2016_CLASSES:
            data_dirs.append(item)
    
    if not data_dirs:
        print("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„é£Ÿç‰©ç±»åˆ«ç›®å½•")
        print("ğŸ” è¯·æ£€æŸ¥æ•°æ®é›†ç»“æ„æ˜¯å¦æ­£ç¡®")
        return
    
    print(f"âœ… æ‰¾åˆ° {len(data_dirs)} ä¸ªé£Ÿç‰©ç±»åˆ«")
    
    # ç»Ÿè®¡ä¿¡æ¯
    stats = {'train': 0, 'val': 0, 'test': 0}
    class_stats = {}
    
    # å¤„ç†æ¯ä¸ªç±»åˆ«
    for class_dir in data_dirs:
        class_name = class_dir.name
        class_id = UNIMIB2016_CLASSES[class_name]
        
        # è·å–è¯¥ç±»åˆ«çš„æ‰€æœ‰å›¾åƒ
        image_files = []
        for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.JPG', '*.JPEG', '*.PNG']:
            image_files.extend(class_dir.glob(ext))
        
        if not image_files:
            print(f"âš ï¸ ç±»åˆ« '{class_name}' ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾åƒæ–‡ä»¶")
            continue
        
        print(f"ğŸ“Š å¤„ç†ç±»åˆ« '{class_name}': {len(image_files)} å¼ å›¾åƒ")
        
        # éšæœºæ‰“ä¹±å›¾åƒåˆ—è¡¨
        random.shuffle(image_files)
        
        # è®¡ç®—åˆ†å‰²ç‚¹
        total_images = len(image_files)
        train_count = int(total_images * train_ratio)
        val_count = int(total_images * val_ratio)
        
        # åˆ†å‰²æ•°æ®é›†
        train_images = image_files[:train_count]
        val_images = image_files[train_count:train_count + val_count]
        test_images = image_files[train_count + val_count:]
        
        class_stats[class_name] = {
            'train': len(train_images),
            'val': len(val_images),
            'test': len(test_images),
            'total': len(image_files)
        }
        
        # å¤åˆ¶å›¾åƒåˆ°ç›¸åº”ç›®å½•
        for split, images in [('train', train_images), ('val', val_images), ('test', test_images)]:
            if not images:
                continue
                
            for i, img_file in enumerate(images):
                # ç”Ÿæˆæ–°çš„æ–‡ä»¶å
                new_filename = f"{class_id:02d}_{class_name}_{i:04d}{img_file.suffix}"
                target_file = target_path / 'images' / split / new_filename
                
                try:
                    # éªŒè¯å›¾åƒæ–‡ä»¶
                    with Image.open(img_file) as img:
                        img.verify()
                    
                    # å¤åˆ¶æ–‡ä»¶
                    shutil.copy2(img_file, target_file)
                    stats[split] += 1
                    
                except Exception as e:
                    print(f"âŒ è·³è¿‡æŸåçš„å›¾åƒ: {img_file} ({e})")
    
    # ä¿å­˜è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
    stats_file = target_path / 'dataset_stats.json'
    with open(stats_file, 'w', encoding='utf-8') as f:
        json.dump({
            'total_stats': stats,
            'class_stats': class_stats,
            'dataset_info': {
                'name': 'UNIMIB2016',
                'total_classes': len(class_stats),
                'train_ratio': train_ratio,
                'val_ratio': val_ratio,
                'test_ratio': 1 - train_ratio - val_ratio
            }
        }, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“ˆ UNIMIB2016 æ•°æ®é›†å¤„ç†å®Œæˆ:")
    print(f"è®­ç»ƒé›†: {stats['train']} å¼ å›¾åƒ")
    print(f"éªŒè¯é›†: {stats['val']} å¼ å›¾åƒ")
    print(f"æµ‹è¯•é›†: {stats['test']} å¼ å›¾åƒ")
    print(f"æ€»è®¡: {sum(stats.values())} å¼ å›¾åƒ")
    print(f"ç±»åˆ«æ•°: {len(class_stats)}")
    print(f"ğŸ’¾ è¯¦ç»†ç»Ÿè®¡å·²ä¿å­˜åˆ°: {stats_file}")

def main():
    parser = argparse.ArgumentParser(description='UNIMIB2016 æ•°æ®é›†å¤„ç†å·¥å…·')
    parser.add_argument('--source', type=str, required=True,
                       help='æ•°æ®é›†æºç›®å½•æˆ–zipæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--target', type=str, default='../datasets/unimib2016',
                       help='ç›®æ ‡æ•°æ®ç›®å½•')
    parser.add_argument('--train-ratio', type=float, default=0.7,
                       help='è®­ç»ƒé›†æ¯”ä¾‹')
    parser.add_argument('--val-ratio', type=float, default=0.2,
                       help='éªŒè¯é›†æ¯”ä¾‹')
    parser.add_argument('--extract', action='store_true',
                       help='å¦‚æœæºæ˜¯zipæ–‡ä»¶ï¼Œå…ˆè§£å‹')
    
    args = parser.parse_args()
    
    source_path = Path(args.source)
    
    # å¦‚æœæ˜¯zipæ–‡ä»¶ï¼Œå…ˆè§£å‹
    if args.extract and source_path.suffix.lower() == '.zip':
        extract_dir = source_path.parent / 'extracted'
        extracted_path = extract_kaggle_dataset(source_path, extract_dir)
        source_path = extracted_path
    
    # å¤„ç†æ•°æ®é›†
    process_unimib2016(source_path, args.target, args.train_ratio, args.val_ratio)
    
    print(f"\nğŸ‰ æ•°æ®é›†å¤„ç†å®Œæˆï¼")
    print(f"ğŸ“ æ•°æ®é›†ä½ç½®: {args.target}")
    print(f"âš¡ ç°åœ¨å¯ä»¥å¼€å§‹è®­ç»ƒäº†:")
    print(f"   python train_food_classification.py --data data/unimib2016.yaml --model yolov5s-cls.pt --epochs 50")

if __name__ == '__main__':
    main()
