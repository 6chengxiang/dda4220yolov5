#!/usr/bin/env python3
"""
å¯è§†åŒ–æµ‹è¯•è„šæœ¬
Visual Test Script

ç”Ÿæˆå¸¦æœ‰é¢„æµ‹ç»“æœçš„å¯è§†åŒ–å›¾åƒ
"""

import argparse
import torch
import cv2
import numpy as np
from pathlib import Path
import sys
from PIL import Image, ImageDraw, ImageFont
import matplotlib.pyplot as plt
import seaborn as sns

# æ·»åŠ  YOLOv5 è·¯å¾„
FILE = Path(__file__).resolve()
ROOT = FILE.parents[0]
if str(ROOT) not in sys.path:
    sys.path.append(str(ROOT))

# UNIMIB2016 ç±»åˆ«åç§°
FOOD_CLASSES = {
    0: 'é¢åŒ…', 1: 'ç•ªèŒ„é…±æ„é¢', 2: 'è‚‰é…±æ„é¢', 3: 'è›¤èœŠé…±æ„é¢', 4: 'é’é…±æ„é¢',
    5: 'è’œè“‰æ©„æ¦„æ²¹æ„é¢', 6: 'ç•ªèŒ„é…±åœŸè±†å›¢å­', 7: 'é’é…±åœŸè±†å›¢å­', 8: 'æ„å¼çƒ©é¥­', 9: 'ç‰ç±³ç²¥',
    10: 'ç›æ ¼ä¸½ç‰¹æŠ«è¨', 11: 'å››ç§å¥¶é…ªæŠ«è¨', 12: 'è”¬èœæŠ«è¨', 13: 'ç«è…¿æŠ«è¨', 14: 'ä½›å¡å¤é¢åŒ…',
    15: 'è±Œè±†ç«è…¿åŒ…', 16: 'å®½é¢æ¡é…é…±', 17: 'ç•ªèŒ„é…±è‚‰ä¸¸', 18: 'çƒ¤æ„é¢', 19: 'æ„é¢æ²™æ‹‰',
    20: 'è”¬èœæ±¤', 21: 'é±¼æ±¤', 22: 'è”¬èœæ±¤2', 23: 'ç‰›è‚š', 24: 'æ„é¢è±†æ±¤',
    25: 'æ‰˜æ–¯å¡çº³è”¬èœæ±¤', 26: 'çƒ¤é±¼', 27: 'ä»€é”¦ç‚¸é±¼', 28: 'è£¹ç²‰ç‚¸é±¼', 29: 'çƒ¤é¸¡',
    30: 'é¸¡èƒ¸è‚‰', 31: 'é¸¡ç¿…', 32: 'ç‚¸é¸¡', 33: 'å°ç‰›æ’', 34: 'çƒ¤ç‰›è‚‰',
    35: 'ç‚–ç‰›è‚‰', 36: 'çƒ¤ç‰›è‚‰2', 37: 'æ±‰å ¡', 38: 'çŒªæ’', 39: 'çŒªé‡Œè„Š',
    40: 'çƒ¤çŒªè‚‰', 41: 'ç”Ÿç«è…¿', 42: 'ç†Ÿç«è…¿', 43: 'ç…è›‹', 44: 'ç‚’è›‹',
    45: 'æ°´ç…®è›‹', 46: 'ç…è›‹å·', 47: 'å¥¶é…ª', 48: 'é©¬è‹é‡Œæ‹‰å¥¶é…ª', 49: 'èŒ…å±‹å¥¶é…ª',
    50: 'é…¸å¥¶', 51: 'è‹¹æœ', 52: 'é¦™è•‰', 53: 'æ©™å­', 54: 'è‰è“',
    55: 'è‘¡è„', 56: 'æ¢¨', 57: 'æ¡ƒå­', 58: 'æŸ æª¬', 59: 'çŒ•çŒ´æ¡ƒ',
    60: 'è è', 61: 'æ··åˆæ²™æ‹‰', 62: 'èƒ¡èåœ', 63: 'é’è±†', 64: 'è èœ',
    65: 'ç•ªèŒ„', 66: 'åœŸè±†', 67: 'è–¯æ¡', 68: 'çƒ¤åœŸè±†', 69: 'æ°´ç…®åœŸè±†',
    70: 'åœŸè±†å›¢å­', 71: 'è‘¡è„é…’', 72: 'æ°´'
}

def predict_image(model, image_path, device='cpu'):
    """é¢„æµ‹å•å¼ å›¾åƒ"""
    try:
        # åŠ è½½å›¾åƒ
        img = Image.open(image_path).convert('RGB')
        img_array = np.array(img)
        
        # è½¬æ¢ä¸ºtensor
        img_tensor = torch.from_numpy(img_array).to(device)
        img_tensor = img_tensor.permute(2, 0, 1).float() / 255.0
        img_tensor = img_tensor.unsqueeze(0)
        
        # é¢„æµ‹
        with torch.no_grad():
            pred = model(img_tensor)
        
        # å¤„ç†é¢„æµ‹ç»“æœ
        if hasattr(pred, 'softmax'):
            probs = pred.softmax(1)
        else:
            probs = torch.softmax(pred, dim=1)
        
        # è·å–top5é¢„æµ‹
        top5_probs, top5_indices = torch.topk(probs[0], 5)
        
        results = []
        for prob, idx in zip(top5_probs, top5_indices):
            class_id = idx.item()
            confidence = prob.item()
            class_name = FOOD_CLASSES.get(class_id, f'æœªçŸ¥_{class_id}')
            results.append({
                'class_id': class_id,
                'class_name': class_name,
                'confidence': confidence
            })
        
        return img, results
        
    except Exception as e:
        print(f"âŒ é¢„æµ‹å¤±è´¥: {e}")
        return None, None

def create_result_image(image, predictions, save_path):
    """åˆ›å»ºå¸¦æœ‰é¢„æµ‹ç»“æœçš„å›¾åƒ"""
    # è½¬æ¢ä¸ºPILå›¾åƒ
    if isinstance(image, np.ndarray):
        img = Image.fromarray(image)
    else:
        img = image.copy()
    
    # åˆ›å»ºç»˜å›¾å¯¹è±¡
    draw = ImageDraw.Draw(img)
    
    # å°è¯•åŠ è½½å­—ä½“
    try:
        # Windowsç³»ç»Ÿçš„ä¸­æ–‡å­—ä½“
        font_large = ImageFont.truetype("msyh.ttc", 32)  # å¾®è½¯é›…é»‘
        font_small = ImageFont.truetype("msyh.ttc", 24)
    except:
        try:
            # å¤‡ç”¨å­—ä½“
            font_large = ImageFont.truetype("arial.ttf", 32)
            font_small = ImageFont.truetype("arial.ttf", 24)
        except:
            # é»˜è®¤å­—ä½“
            font_large = ImageFont.load_default()
            font_small = ImageFont.load_default()
    
    # è·å–å›¾åƒå°ºå¯¸
    width, height = img.size
    
    # åˆ›å»ºåŠé€æ˜èƒŒæ™¯
    overlay = Image.new('RGBA', (width, height), (0, 0, 0, 0))
    overlay_draw = ImageDraw.Draw(overlay)
    
    # ç»˜åˆ¶ç»“æœèƒŒæ™¯
    result_height = 200
    overlay_draw.rectangle(
        [(0, height - result_height), (width, height)],
        fill=(0, 0, 0, 180)
    )
    
    # åˆæˆå›¾åƒ
    img = Image.alpha_composite(img.convert('RGBA'), overlay).convert('RGB')
    draw = ImageDraw.Draw(img)
    
    # ç»˜åˆ¶é¢„æµ‹ç»“æœ
    y_start = height - result_height + 10
    
    # æ ‡é¢˜
    draw.text((10, y_start), "ğŸ• é£Ÿç‰©åˆ†ç±»ç»“æœ", fill='white', font=font_large)
    
    # é¢„æµ‹ç»“æœ
    for i, pred in enumerate(predictions[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ª
        y_pos = y_start + 40 + i * 35
        
        # ç½®ä¿¡åº¦æ¡
        conf_width = int(300 * pred['confidence'])
        draw.rectangle(
            [(10, y_pos + 20), (310, y_pos + 30)],
            outline='white', width=1
        )
        draw.rectangle(
            [(10, y_pos + 20), (10 + conf_width, y_pos + 30)],
            fill='green' if i == 0 else 'orange'
        )
        
        # æ–‡æœ¬
        text = f"{i+1}. {pred['class_name']} ({pred['confidence']:.1%})"
        draw.text((10, y_pos), text, fill='white', font=font_small)
    
    # ä¿å­˜å›¾åƒ
    img.save(save_path)
    print(f"ğŸ’¾ ç»“æœå›¾åƒå·²ä¿å­˜: {save_path}")
    
    return img

def create_comparison_grid(image_results, save_path, grid_size=(3, 3)):
    """åˆ›å»ºå¯¹æ¯”ç½‘æ ¼å›¾åƒ"""
    rows, cols = grid_size
    max_images = min(len(image_results), rows * cols)
    
    if max_images == 0:
        print("âŒ æ²¡æœ‰å›¾åƒç»“æœå¯æ˜¾ç¤º")
        return
    
    # è®¡ç®—å•ä¸ªå›¾åƒå¤§å°
    img_width, img_height = 300, 300
    
    # åˆ›å»ºç½‘æ ¼å›¾åƒ
    grid_width = cols * img_width
    grid_height = rows * (img_height + 60)  # é¢å¤–ç©ºé—´ç”¨äºæ–‡æœ¬
    
    grid_img = Image.new('RGB', (grid_width, grid_height), 'white')
    
    # å­—ä½“
    try:
        font = ImageFont.truetype("msyh.ttc", 16)
    except:
        font = ImageFont.load_default()
    
    for i in range(max_images):
        row = i // cols
        col = i % cols
        
        img_path, predictions = image_results[i]
        
        # åŠ è½½å¹¶è°ƒæ•´å›¾åƒå¤§å°
        try:
            img = Image.open(img_path).convert('RGB')
            img = img.resize((img_width, img_height))
            
            # ç²˜è´´åˆ°ç½‘æ ¼
            x = col * img_width
            y = row * (img_height + 60)
            grid_img.paste(img, (x, y))
            
            # æ·»åŠ é¢„æµ‹æ–‡æœ¬
            draw = ImageDraw.Draw(grid_img)
            text_y = y + img_height + 5
            
            # æ–‡ä»¶å
            filename = Path(img_path).name
            draw.text((x + 5, text_y), f"ğŸ“ {filename}", fill='black', font=font)
            
            # æœ€ä½³é¢„æµ‹
            if predictions:
                best_pred = predictions[0]
                pred_text = f"ğŸ• {best_pred['class_name']} ({best_pred['confidence']:.1%})"
                draw.text((x + 5, text_y + 20), pred_text, fill='green', font=font)
            
        except Exception as e:
            print(f"âš ï¸ å¤„ç†å›¾åƒå¤±è´¥ {img_path}: {e}")
    
    # ä¿å­˜ç½‘æ ¼å›¾åƒ
    grid_img.save(save_path)
    print(f"ğŸ“Š å¯¹æ¯”ç½‘æ ¼å·²ä¿å­˜: {save_path}")
    
    return grid_img

def main():
    parser = argparse.ArgumentParser(description='å¯è§†åŒ–æµ‹è¯•è„šæœ¬')
    parser.add_argument('--weights', type=str, required=True,
                       help='æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--source', type=str, required=True,
                       help='å›¾åƒæ–‡ä»¶æˆ–ç›®å½•è·¯å¾„')
    parser.add_argument('--device', default='cpu',
                       help='æ¨ç†è®¾å¤‡ (cpu, 0, 1, 2, 3, ...)')
    parser.add_argument('--output', type=str, default='runs/visual_test',
                       help='è¾“å‡ºç›®å½•')
    parser.add_argument('--grid', action='store_true',
                       help='åˆ›å»ºå¯¹æ¯”ç½‘æ ¼')
    parser.add_argument('--max-images', type=int, default=9,
                       help='æœ€å¤§å¤„ç†å›¾åƒæ•°')
    
    args = parser.parse_args()
    
    print("ğŸ¨ å¯è§†åŒ–æµ‹è¯•è„šæœ¬")
    print(f"ğŸ“‚ æ¨¡å‹: {args.weights}")
    print(f"ğŸ–¼ï¸ æº: {args.source}")
    print("-" * 40)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # åŠ è½½æ¨¡å‹
    print("ğŸ—ï¸ åŠ è½½æ¨¡å‹...")
    try:
        # ä½¿ç”¨YOLOv5åˆ†ç±»æ¨¡å‹
        model = torch.hub.load('ultralytics/yolov5', 'custom', 
                              path=args.weights, device=args.device)
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return
    
    source_path = Path(args.source)
    image_results = []
    
    if source_path.is_file():
        # å•å¼ å›¾åƒ
        print(f"ğŸ“¸ å¤„ç†å•å¼ å›¾åƒ: {source_path.name}")
        
        img, predictions = predict_image(model, source_path, args.device)
        if img and predictions:
            # åˆ›å»ºç»“æœå›¾åƒ
            result_path = output_dir / f"result_{source_path.stem}.jpg"
            create_result_image(img, predictions, result_path)
            
            # æ˜¾ç¤ºç»“æœ
            print(f"\nğŸ“Š é¢„æµ‹ç»“æœ:")
            for i, pred in enumerate(predictions):
                print(f"  {i+1}. {pred['class_name']}: {pred['confidence']:.3f}")
    
    elif source_path.is_dir():
        # å›¾åƒç›®å½•
        print(f"ğŸ“ å¤„ç†å›¾åƒç›®å½•: {source_path}")
        
        # æŸ¥æ‰¾å›¾åƒæ–‡ä»¶
        image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}
        image_files = []
        for ext in image_extensions:
            image_files.extend(source_path.glob(f'*{ext}'))
            image_files.extend(source_path.glob(f'*{ext.upper()}'))
        
        if not image_files:
            print("âŒ æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶")
            return
        
        # é™åˆ¶æ•°é‡
        image_files = image_files[:args.max_images]
        print(f"ğŸ” æ‰¾åˆ° {len(image_files)} å¼ å›¾åƒ")
        
        # å¤„ç†æ¯å¼ å›¾åƒ
        for i, img_path in enumerate(image_files):
            print(f"\nğŸ“¸ å¤„ç† {i+1}/{len(image_files)}: {img_path.name}")
            
            img, predictions = predict_image(model, img_path, args.device)
            if img and predictions:
                # åˆ›å»ºç»“æœå›¾åƒ
                result_path = output_dir / f"result_{img_path.stem}.jpg"
                create_result_image(img, predictions, result_path)
                
                # ä¿å­˜ç»“æœç”¨äºç½‘æ ¼
                image_results.append((img_path, predictions))
                
                # æ˜¾ç¤ºæœ€ä½³é¢„æµ‹
                best_pred = predictions[0]
                print(f"  ğŸ† æœ€ä½³é¢„æµ‹: {best_pred['class_name']} ({best_pred['confidence']:.3f})")
        
        # åˆ›å»ºå¯¹æ¯”ç½‘æ ¼
        if args.grid and image_results:
            print(f"\nğŸ“Š åˆ›å»ºå¯¹æ¯”ç½‘æ ¼...")
            grid_path = output_dir / "comparison_grid.jpg"
            create_comparison_grid(image_results, grid_path)
    
    else:
        print(f"âŒ æ— æ•ˆçš„æºè·¯å¾„: {source_path}")
        return
    
    print(f"\nğŸ‰ å¯è§†åŒ–æµ‹è¯•å®Œæˆï¼")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {output_dir}")

if __name__ == '__main__':
    main()
