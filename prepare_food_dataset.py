#!/usr/bin/env python3
"""
é£Ÿç‰©æ•°æ®é›†å‡†å¤‡è„šæœ¬
Food Dataset Preparation Script

å¸®åŠ©å‡†å¤‡å’Œç»„ç»‡é£Ÿç‰©åˆ†ç±»æ•°æ®é›†
"""

import os
import shutil
import argparse
from pathlib import Path
import random
from PIL import Image
import json

def create_dataset_structure(dataset_path):
    """åˆ›å»ºæ ‡å‡†çš„æ•°æ®é›†ç›®å½•ç»“æ„"""
    dataset_path = Path(dataset_path)
    
    # åˆ›å»ºç›®å½•ç»“æ„
    dirs_to_create = [
        dataset_path / 'images' / 'train',
        dataset_path / 'images' / 'val',
        dataset_path / 'images' / 'test',
    ]
    
    for dir_path in dirs_to_create:
        dir_path.mkdir(parents=True, exist_ok=True)
        print(f"âœ… åˆ›å»ºç›®å½•: {dir_path}")

def organize_images_by_class(source_dir, target_dir, train_ratio=0.7, val_ratio=0.2):
    """
    å°†æŒ‰ç±»åˆ«ç»„ç»‡çš„å›¾åƒåˆ†å‰²ä¸ºè®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†
    
    é¢„æœŸçš„æºç›®å½•ç»“æ„:
    source_dir/
    â”œâ”€â”€ è‹¹æœ/
    â”‚   â”œâ”€â”€ image1.jpg
    â”‚   â””â”€â”€ image2.jpg
    â”œâ”€â”€ é¦™è•‰/
    â”‚   â”œâ”€â”€ image1.jpg
    â”‚   â””â”€â”€ image2.jpg
    â””â”€â”€ ...
    """
    source_path = Path(source_dir)
    target_path = Path(target_dir)
    
    # åˆ›å»ºç›®æ ‡ç›®å½•ç»“æ„
    create_dataset_structure(target_path)
    
    # ç±»åˆ«æ˜ å°„
    class_mapping = {}
    class_id = 0
    
    # ç»Ÿè®¡ä¿¡æ¯
    stats = {'train': 0, 'val': 0, 'test': 0}
    
    print(f"ğŸ“ å¤„ç†æºç›®å½•: {source_path}")
    
    # éå†æ¯ä¸ªç±»åˆ«ç›®å½•
    for class_dir in source_path.iterdir():
        if not class_dir.is_dir():
            continue
            
        class_name = class_dir.name
        class_mapping[class_id] = class_name
        
        # è·å–è¯¥ç±»åˆ«çš„æ‰€æœ‰å›¾åƒ
        image_files = []
        for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:
            image_files.extend(class_dir.glob(ext))
            image_files.extend(class_dir.glob(ext.upper()))
        
        if not image_files:
            print(f"âš ï¸ ç±»åˆ« '{class_name}' ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾åƒæ–‡ä»¶")
            continue
        
        print(f"ğŸ“Š ç±»åˆ« '{class_name}': {len(image_files)} å¼ å›¾åƒ")
        
        # éšæœºæ‰“ä¹±å›¾åƒåˆ—è¡¨
        random.shuffle(image_files)
        
        # è®¡ç®—åˆ†å‰²ç‚¹
        total_images = len(image_files)
        train_count = int(total_images * train_ratio)
        val_count = int(total_images * val_ratio)
        
        # åˆ†å‰²æ•°æ®é›†
        train_images = image_files[:train_count]
        val_images = image_files[train_count:train_count + val_count]
        test_images = image_files[train_count + val_count:]
        
        # å¤åˆ¶å›¾åƒåˆ°ç›¸åº”ç›®å½•
        for split, images in [('train', train_images), ('val', val_images), ('test', test_images)]:
            if not images:
                continue
                
            for img_file in images:
                # ç”Ÿæˆæ–°çš„æ–‡ä»¶åï¼ˆåŒ…å«ç±»åˆ«IDï¼‰
                new_filename = f"{class_id:02d}_{class_name}_{img_file.stem}{img_file.suffix}"
                target_file = target_path / 'images' / split / new_filename
                
                try:
                    # éªŒè¯å›¾åƒæ–‡ä»¶
                    with Image.open(img_file) as img:
                        img.verify()
                    
                    # å¤åˆ¶æ–‡ä»¶
                    shutil.copy2(img_file, target_file)
                    stats[split] += 1
                    
                except Exception as e:
                    print(f"âŒ è·³è¿‡æŸåçš„å›¾åƒ: {img_file} ({e})")
        
        class_id += 1
    
    # ä¿å­˜ç±»åˆ«æ˜ å°„
    mapping_file = target_path / 'class_mapping.json'
    with open(mapping_file, 'w', encoding='utf-8') as f:
        json.dump(class_mapping, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“ˆ æ•°æ®é›†ç»Ÿè®¡:")
    print(f"è®­ç»ƒé›†: {stats['train']} å¼ å›¾åƒ")
    print(f"éªŒè¯é›†: {stats['val']} å¼ å›¾åƒ") 
    print(f"æµ‹è¯•é›†: {stats['test']} å¼ å›¾åƒ")
    print(f"æ€»è®¡: {sum(stats.values())} å¼ å›¾åƒ")
    print(f"ç±»åˆ«æ•°: {class_id}")
    print(f"ğŸ’¾ ç±»åˆ«æ˜ å°„å·²ä¿å­˜åˆ°: {mapping_file}")

def download_food101_sample():
    """ä¸‹è½½ Food-101 æ•°æ®é›†çš„ç¤ºä¾‹"""
    print("ğŸ“¥ Food-101 æ•°æ®é›†ä¸‹è½½æŒ‡å—:")
    print("1. è®¿é—®: https://www.vision.ee.ethz.ch/datasets_extra/food-101/")
    print("2. ä¸‹è½½ food-101.tar.gz æ–‡ä»¶")
    print("3. è§£å‹åˆ° ../datasets/ ç›®å½•")
    print("4. è¿è¡Œæœ¬è„šæœ¬æ•´ç†æ•°æ®é›†ç»“æ„")
    
    print("\nğŸ’¡ æˆ–è€…ï¼Œæ‚¨å¯ä»¥:")
    print("1. ä½¿ç”¨è‡ªå·±æ”¶é›†çš„é£Ÿç‰©å›¾åƒ")
    print("2. ä»ç½‘ç»œçˆ¬å–é£Ÿç‰©å›¾åƒ")
    print("3. ä½¿ç”¨ Google Images, Unsplash ç­‰å…è´¹å›¾åƒèµ„æº")

def create_sample_dataset(target_dir, num_classes=5, images_per_class=50):
    """åˆ›å»ºç¤ºä¾‹æ•°æ®é›†ç»“æ„ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
    target_path = Path(target_dir)
    create_dataset_structure(target_path)
    
    sample_classes = ['è‹¹æœ', 'é¦™è•‰', 'æŠ«è¨', 'æ±‰å ¡', 'è›‹ç³•'][:num_classes]
    
    print(f"ğŸ§ª åˆ›å»ºç¤ºä¾‹æ•°æ®é›†ç»“æ„")
    print(f"ğŸ“ ç›®æ ‡ç›®å½•: {target_path}")
    print(f"ğŸ“Š ç±»åˆ«æ•°: {num_classes}")
    print(f"ğŸ–¼ï¸ æ¯ç±»å›¾åƒæ•°: {images_per_class}")
    
    for class_id, class_name in enumerate(sample_classes):
        for split in ['train', 'val', 'test']:
            split_dir = target_path / 'images' / split
            
            # æ ¹æ®åˆ†å‰²æ¯”ä¾‹åˆ†é…å›¾åƒæ•°é‡
            if split == 'train':
                count = int(images_per_class * 0.7)
            elif split == 'val':
                count = int(images_per_class * 0.2)
            else:
                count = int(images_per_class * 0.1)
            
            for i in range(count):
                # åˆ›å»ºå ä½ç¬¦æ–‡ä»¶
                placeholder_file = split_dir / f"{class_id:02d}_{class_name}_{i:03d}.txt"
                with open(placeholder_file, 'w', encoding='utf-8') as f:
                    f.write(f"è¿™æ˜¯ {class_name} ç±»åˆ«çš„ç¬¬ {i+1} å¼ å›¾åƒçš„å ä½ç¬¦\n")
                    f.write(f"è¯·æ›¿æ¢ä¸ºå®é™…çš„ {class_name} å›¾åƒæ–‡ä»¶\n")
    
    print("âœ… ç¤ºä¾‹æ•°æ®é›†ç»“æ„åˆ›å»ºå®Œæˆ")
    print("ğŸ“ è¯·å°†å ä½ç¬¦æ–‡ä»¶æ›¿æ¢ä¸ºå®é™…çš„å›¾åƒæ–‡ä»¶")

def main():
    parser = argparse.ArgumentParser(description='é£Ÿç‰©æ•°æ®é›†å‡†å¤‡å·¥å…·')
    parser.add_argument('--mode', choices=['organize', 'download', 'sample'], 
                       required=True, help='è¿è¡Œæ¨¡å¼')
    parser.add_argument('--source', type=str, 
                       help='æºæ•°æ®ç›®å½•ï¼ˆorganize æ¨¡å¼ï¼‰')
    parser.add_argument('--target', type=str, 
                       help='ç›®æ ‡æ•°æ®ç›®å½•')
    parser.add_argument('--train-ratio', type=float, default=0.7,
                       help='è®­ç»ƒé›†æ¯”ä¾‹')
    parser.add_argument('--val-ratio', type=float, default=0.2,
                       help='éªŒè¯é›†æ¯”ä¾‹')
    parser.add_argument('--num-classes', type=int, default=5,
                       help='ç¤ºä¾‹ç±»åˆ«æ•°ï¼ˆsample æ¨¡å¼ï¼‰')
    parser.add_argument('--images-per-class', type=int, default=50,
                       help='æ¯ç±»å›¾åƒæ•°ï¼ˆsample æ¨¡å¼ï¼‰')
    
    args = parser.parse_args()
    
    if args.mode == 'organize':
        if not args.source or not args.target:
            print("âŒ organize æ¨¡å¼éœ€è¦æŒ‡å®š --source å’Œ --target å‚æ•°")
            return
        organize_images_by_class(args.source, args.target, 
                               args.train_ratio, args.val_ratio)
    
    elif args.mode == 'download':
        download_food101_sample()
    
    elif args.mode == 'sample':
        if not args.target:
            args.target = '../datasets/food-sample'
        create_sample_dataset(args.target, args.num_classes, args.images_per_class)

if __name__ == '__main__':
    main()
